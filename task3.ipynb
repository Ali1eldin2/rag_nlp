{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77df7bec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 1 — Imports & metric functions\n",
    "import os\n",
    "import math\n",
    "import csv\n",
    "from typing import List, Dict, Any\n",
    "from collections import defaultdict\n",
    "\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "\n",
    "# Robust doc id extractor (works with LangChain Document objects)\n",
    "def _get_doc_id(doc):\n",
    "    if hasattr(doc, \"metadata\") and isinstance(doc.metadata, dict):\n",
    "        for key in (\"id\", \"source\", \"doc_id\", \"document_id\"):\n",
    "            if key in doc.metadata:\n",
    "                return str(doc.metadata[key])\n",
    "        if \"source\" in doc.metadata:\n",
    "            return str(doc.metadata[\"source\"])\n",
    "    if hasattr(doc, \"id\"):\n",
    "        return str(getattr(doc, \"id\"))\n",
    "    return str(hash(getattr(doc, \"page_content\", \"\")[:200]))\n",
    "\n",
    "def precision_at_k(retrieved_ids: List[str], relevant_ids: set, k: int) -> float:\n",
    "    topk = retrieved_ids[:k]\n",
    "    if len(topk) == 0:\n",
    "        return 0.0\n",
    "    tp = sum(1 for i in topk if i in relevant_ids)\n",
    "    return tp / len(topk)\n",
    "\n",
    "def recall_at_k(retrieved_ids: List[str], relevant_ids: set, k: int) -> float:\n",
    "    topk = retrieved_ids[:k]\n",
    "    if len(relevant_ids) == 0:\n",
    "        return 0.0\n",
    "    tp = sum(1 for i in topk if i in relevant_ids)\n",
    "    return tp / len(relevant_ids)\n",
    "\n",
    "def reciprocal_rank(retrieved_ids: List[str], relevant_ids: set) -> float:\n",
    "    for idx, doc_id in enumerate(retrieved_ids, start=1):\n",
    "        if doc_id in relevant_ids:\n",
    "            return 1.0 / idx\n",
    "    return 0.0\n",
    "\n",
    "def dcg_at_k(retrieved_ids: List[str], rel_scores: Dict[str, float], k:int) -> float:\n",
    "    dcg = 0.0\n",
    "    for i, doc_id in enumerate(retrieved_ids[:k], start=1):\n",
    "        rel = rel_scores.get(doc_id, 0.0)\n",
    "        dcg += (2**rel - 1) / math.log2(i + 1)\n",
    "    return dcg\n",
    "\n",
    "def ndcg_at_k(retrieved_ids: List[str], rel_scores: Dict[str, float], k:int) -> float:\n",
    "    dcg = dcg_at_k(retrieved_ids, rel_scores, k)\n",
    "    ideal_rels = sorted(rel_scores.values(), reverse=True)[:k]\n",
    "    idcg = 0.0\n",
    "    for i, rel in enumerate(ideal_rels, start=1):\n",
    "        idcg += (2**rel - 1) / math.log2(i + 1)\n",
    "    if idcg == 0:\n",
    "        return 0.0\n",
    "    return dcg / idcg\n",
    "\n",
    "def evaluate_retriever(\n",
    "    vectorstore,\n",
    "    test_queries: List[Dict[str,Any]],\n",
    "    k_values: List[int] = [1,3,5],\n",
    "    return_per_query: bool = False\n",
    "):\n",
    "    results = {k: {\"precision\": [], \"recall\": [], \"mr\": [], \"ndcg\": []} for k in k_values}\n",
    "    per_query = []\n",
    "\n",
    "    for q in test_queries:\n",
    "        query_text = q[\"query\"]\n",
    "        relevant_ids = set(map(str, q.get(\"relevant_docs\", [])))\n",
    "        rel_scores = {str(d): float(s) for d, s in q.get(\"rel_scores\", {}).items()} if q.get(\"rel_scores\") else {rid:1.0 for rid in relevant_ids}\n",
    "\n",
    "        max_k = max(k_values)\n",
    "        docs = vectorstore.similarity_search(query_text, k=max_k)\n",
    "        retrieved_ids = [_get_doc_id(d) for d in docs]\n",
    "\n",
    "        query_metrics = {\"query\": query_text}\n",
    "        for k in k_values:\n",
    "            p = precision_at_k(retrieved_ids, relevant_ids, k)\n",
    "            r = recall_at_k(retrieved_ids, relevant_ids, k)\n",
    "            rr = reciprocal_rank(retrieved_ids, relevant_ids)\n",
    "            ndcg = ndcg_at_k(retrieved_ids, rel_scores, k)\n",
    "            results[k][\"precision\"].append(p)\n",
    "            results[k][\"recall\"].append(r)\n",
    "            results[k][\"mr\"].append(rr)\n",
    "            results[k][\"ndcg\"].append(ndcg)\n",
    "            query_metrics[f\"P@{k}\"] = p\n",
    "            query_metrics[f\"R@{k}\"] = r\n",
    "            query_metrics[f\"RR\"] = rr\n",
    "            query_metrics[f\"nDCG@{k}\"] = ndcg\n",
    "\n",
    "        per_query.append(query_metrics)\n",
    "\n",
    "    summary = {}\n",
    "    for k in k_values:\n",
    "        summary[k] = {\n",
    "            \"precision@{}\".format(k): sum(results[k][\"precision\"]) / len(results[k][\"precision\"]) if results[k][\"precision\"] else 0.0,\n",
    "            \"recall@{}\".format(k): sum(results[k][\"recall\"]) / len(results[k][\"recall\"]) if results[k][\"recall\"] else 0.0,\n",
    "            \"MRR\": sum(results[k][\"mr\"]) / len(results[k][\"mr\"]) if results[k][\"mr\"] else 0.0,\n",
    "            \"nDCG@{}\".format(k): sum(results[k][\"ndcg\"]) / len(results[k][\"ndcg\"]) if results[k][\"ndcg\"] else 0.0,\n",
    "        }\n",
    "\n",
    "    if return_per_query:\n",
    "        return {\"summary\": summary, \"per_query\": per_query}\n",
    "    return {\"summary\": summary}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "94dab13d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading Chroma from ./chroma_db\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Alieldin\\AppData\\Local\\Temp\\ipykernel_40516\\615291634.py:20: LangChainDeprecationWarning: The class `HuggingFaceEmbeddings` was deprecated in LangChain 0.2.2 and will be removed in 1.0. An updated version of the class exists in the `langchain-huggingface package and should be used instead. To use it run `pip install -U `langchain-huggingface` and import as `from `langchain_huggingface import HuggingFaceEmbeddings``.\n",
      "  embeddings = HuggingFaceEmbeddings(model_name=\"sentence-transformers/all-MiniLM-L6-v2\")\n",
      "d:\\anconda\\envs\\rag\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chroma loaded.\n"
     ]
    }
   ],
   "source": [
    "# Cell 2 — Load the existing Chroma DB (or use in-memory variable)\n",
    "# Try to reuse a `vectorstore` variable if it already exists in this notebook.\n",
    "try:\n",
    "    vectorstore  # noqa: F821\n",
    "    print(\"Using existing 'vectorstore' variable in notebook.\")\n",
    "except NameError:\n",
    "    # import Chroma loader depending on your environment\n",
    "    try:\n",
    "        from langchain_chroma import Chroma\n",
    "    except Exception:\n",
    "        # fallback to community import\n",
    "        from langchain_community.vectorstores import Chroma\n",
    "\n",
    "    persist_directory = \"./chroma_db\"\n",
    "    if os.path.exists(persist_directory):\n",
    "        print(\"Loading Chroma from\", persist_directory)\n",
    "        # Use the same embedding function you used originally (HuggingFaceEmbeddings)\n",
    "        try:\n",
    "            from langchain_community.embeddings import HuggingFaceEmbeddings\n",
    "            embeddings = HuggingFaceEmbeddings(model_name=\"sentence-transformers/all-MiniLM-L6-v2\")\n",
    "            vectorstore = Chroma(persist_directory=persist_directory, embedding_function=embeddings)\n",
    "        except Exception:\n",
    "            # generic loader\n",
    "            vectorstore = Chroma(persist_directory=persist_directory)\n",
    "        print(\"Chroma loaded.\")\n",
    "    else:\n",
    "        raise RuntimeError(\"No 'vectorstore' variable and no './chroma_db' directory found. Run Task 3 to build it first.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bf767f13",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 1 chunks (sample). Showing id + preview:\n",
      "\n",
      "[0] id=e706b047-2538-4191-abdd-a686efc58efa  preview=Artificial Intelligence (AI) enables machines to learn from experience,     adapt to new inputs, and perform human-like tasks.\n"
     ]
    }
   ],
   "source": [
    "# Cell 3 — Inspect documents stored in Chroma\n",
    "# We'll retrieve all stored documents (or a sample) and print id + preview\n",
    "docs_all = vectorstore._collection.get()[\"documents\"] if hasattr(vectorstore, \"_collection\") else None\n",
    "\n",
    "# Safer approach: use similarity_search with an empty query or re-fetch by retrieving top-n for a random token\n",
    "sample_docs = vectorstore.similarity_search(\"\", k=50)  # many vectorstores ignore empty query but still return top items\n",
    "print(f\"Found {len(sample_docs)} chunks (sample). Showing id + preview:\\n\")\n",
    "for i, d in enumerate(sample_docs):\n",
    "    doc_id = _get_doc_id(d)\n",
    "    preview = getattr(d, \"page_content\", \"\")[:220].replace(\"\\n\", \" \")\n",
    "    print(f\"[{i}] id={doc_id}  preview={preview}\")\n",
    "    if i >= 29:\n",
    "        break\n",
    "\n",
    "# If sample_docs is empty, try reading splits if you have the 'splits' variable\n",
    "if not sample_docs:\n",
    "    try:\n",
    "        print(\"No sample from vectorstore; checking for 'splits' variable in notebook...\")\n",
    "        for i, d in enumerate(splits):\n",
    "            print(f\"[{i}] id={_get_doc_id(d)} preview={d.page_content[:200].replace(chr(10),' ')}\")\n",
    "            if i >= 29:\n",
    "                break\n",
    "    except Exception:\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "037fa9b5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prepared test_queries (preview):\n",
      "{'query': 'What can AI do?', 'relevant_docs': [\"<replace_with_doc_id_that_contains 'Artificial Intelligence' >\"]}\n",
      "{'query': 'Explain deep learning in short', 'relevant_docs': ['<replace_with_another_doc_id>']}\n"
     ]
    }
   ],
   "source": [
    "# Cell 4 — Prepare test queries (two ways)\n",
    "\n",
    "# Option A: manual small test set (recommended for correctness)\n",
    "# Each entry now includes the relevant doc id and an expected answer summary for DeepEval\n",
    "test_queries_manual = [\n",
    "    {\n",
    "        \"name\": \"ai_capabilities\",\n",
    "        \"query\": \"What can artificial intelligence systems do?\",\n",
    "        \"relevant_docs\": [\"ai_overview\"],\n",
    "        \"expected_answer\": \"AI systems can learn from experience, adapt to new inputs, and perform human-like tasks such as perception, reasoning, planning, language understanding, and decision making across many domains.\",\n",
    "    },\n",
    "    {\n",
    "        \"name\": \"deep_learning_definition\",\n",
    "        \"query\": \"Give a short definition of deep learning.\",\n",
    "        \"relevant_docs\": [\"deep_learning_intro\"],\n",
    "        \"expected_answer\": \"Deep learning uses multi-layer neural networks to learn hierarchical feature representations from data and excels on tasks like vision, speech, and language when sufficient data and compute are available.\",\n",
    "    },\n",
    "    {\n",
    "        \"name\": \"training_process\",\n",
    "        \"query\": \"How do neural networks learn during training?\",\n",
    "        \"relevant_docs\": [\"neural_network_training\"],\n",
    "        \"expected_answer\": \"Neural networks learn by comparing predictions to ground truth, computing loss, backpropagating errors, and updating weights with gradient-based optimization over many epochs.\",\n",
    "    },\n",
    "    {\n",
    "        \"name\": \"ml_vs_dl\",\n",
    "        \"query\": \"Differentiate machine learning and deep learning in one sentence.\",\n",
    "        \"relevant_docs\": [\"ml_vs_dl\"],\n",
    "        \"expected_answer\": \"Machine learning covers many algorithms including supervised and unsupervised methods, while deep learning uses deep neural networks to learn end-to-end representations from raw inputs.\",\n",
    "    },\n",
    "]\n",
    "\n",
    "# Option B: heuristic auto-generation (quick, not perfect)\n",
    "# This creates queries by extracting keywords from the first N docs and picking them as 'relevant'\n",
    "def create_heuristic_queries_from_docs(docs, n_queries=5):\n",
    "    queries = []\n",
    "    for d in docs[:n_queries]:\n",
    "        text = getattr(d, \"page_content\", \"\")\n",
    "        # pick first 6 words as a short query heuristic\n",
    "        words = [w for w in text.split() if len(w) > 2]\n",
    "        q = \" \".join(words[:6])\n",
    "        queries.append({\"query\": q, \"relevant_docs\": [_get_doc_id(d)]})\n",
    "    return queries\n",
    "\n",
    "test_queries_auto = create_heuristic_queries_from_docs(sample_docs, n_queries=5)\n",
    "\n",
    "# Choose which to use:\n",
    "test_queries = test_queries_manual  # <--- replace with test_queries_auto to try automatic\n",
    "print(\"Prepared test_queries (preview):\")\n",
    "for t in test_queries:\n",
    "    print(t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c2ba9f5f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== SUMMARY ===\n",
      "K=1:\n",
      "  precision@1: 0.0000\n",
      "  recall@1: 0.0000\n",
      "  MRR: 0.0000\n",
      "  nDCG@1: 0.0000\n",
      "K=3:\n",
      "  precision@3: 0.0000\n",
      "  recall@3: 0.0000\n",
      "  MRR: 0.0000\n",
      "  nDCG@3: 0.0000\n",
      "K=5:\n",
      "  precision@5: 0.0000\n",
      "  recall@5: 0.0000\n",
      "  MRR: 0.0000\n",
      "  nDCG@5: 0.0000\n",
      "\n",
      "=== Per-query results ===\n",
      "{'query': 'What can AI do?', 'P@1': 0.0, 'R@1': 0.0, 'RR': 0.0, 'nDCG@1': 0.0, 'P@3': 0.0, 'R@3': 0.0, 'nDCG@3': 0.0, 'P@5': 0.0, 'R@5': 0.0, 'nDCG@5': 0.0}\n",
      "{'query': 'Explain deep learning in short', 'P@1': 0.0, 'R@1': 0.0, 'RR': 0.0, 'nDCG@1': 0.0, 'P@3': 0.0, 'R@3': 0.0, 'nDCG@3': 0.0, 'P@5': 0.0, 'R@5': 0.0, 'nDCG@5': 0.0}\n"
     ]
    }
   ],
   "source": [
    "# Cell 5 — Evaluate\n",
    "k_values = [1, 3, 5]\n",
    "results = evaluate_retriever(vectorstore, test_queries, k_values=k_values, return_per_query=True)\n",
    "\n",
    "print(\"=== SUMMARY ===\")\n",
    "for k, metrics in results[\"summary\"].items():\n",
    "    print(f\"K={k}:\")\n",
    "    for metric_name, val in metrics.items():\n",
    "        print(f\"  {metric_name}: {val:.4f}\")\n",
    "\n",
    "print(\"\\n=== Per-query results ===\")\n",
    "for pq in results[\"per_query\"]:\n",
    "    print(pq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2f57955",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 6 — Build a simple RAG QA helper (LangChain + OpenAI)\n",
    "if not os.getenv(\"OPENAI_API_KEY\"):\n",
    "    raise EnvironmentError(\n",
    "        \"OPENAI_API_KEY must be set before running the QA chain or DeepEval metrics.\"\n",
    "    )\n",
    "\n",
    "retriever = vectorstore.as_retriever(search_kwargs={\"k\": 3})\n",
    "\n",
    "qa_prompt = ChatPromptTemplate.from_template(\n",
    "    \"\"\"You are a helpful assistant. Answer the user's question using only the provided context.\\n\"\n",
    "    \"\"\"Context:\\n{context}\\n\\nQuestion: {question}\\n\\nAnswer in two concise sentences that stay faithful to the context.\"\"\"\n",
    ")\n",
    "\n",
    "llm = ChatOpenAI(model=\"gpt-4o-mini\", temperature=0.2)\n",
    "parser = StrOutputParser()\n",
    "\n",
    "\n",
    "def run_rag(question: str):\n",
    "    \"\"\"Retrieve supporting chunks and generate an answer.\"\"\"\n",
    "    docs = retriever.invoke(question)\n",
    "    context = \"\\n\\n\".join(doc.page_content for doc in docs)\n",
    "    answer = (qa_prompt | llm | parser).invoke({\"context\": context, \"question\": question})\n",
    "    return answer, docs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d015a41e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Per-query results saved to rag_evaluation_per_query.csv\n"
     ]
    }
   ],
   "source": [
    "# Cell 6 — Save results to CSV\n",
    "out_csv = \"rag_evaluation_per_query.csv\"\n",
    "per_query = results[\"per_query\"]\n",
    "if per_query:\n",
    "    keys = sorted(per_query[0].keys())\n",
    "    with open(out_csv, \"w\", newline=\"\", encoding=\"utf-8\") as f:\n",
    "        writer = csv.DictWriter(f, fieldnames=keys)\n",
    "        writer.writeheader()\n",
    "        for row in per_query:\n",
    "            writer.writerow(row)\n",
    "    print(\"Per-query results saved to\", out_csv)\n",
    "else:\n",
    "    print(\"No per-query results to save.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1517602a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "rag",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
