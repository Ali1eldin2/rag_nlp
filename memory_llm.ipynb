{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "23da8d41",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ✅ Conversational memory in LangChain v1.x\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder\n",
    "from langchain_core.chat_history import InMemoryChatMessageHistory\n",
    "from langchain_core.runnables.history import RunnableWithMessageHistory\n",
    "import os\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f74bec62",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set your API key\n",
    "os.environ[\"OPENAI_API_KEY\"] = \"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\"\n",
    "\n",
    "# Initialize model\n",
    "model = ChatOpenAI(model=\"gpt-4o-mini\", temperature=0.6)\n",
    "\n",
    "# Define a prompt with memory placeholder\n",
    "prompt = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", \"You are a helpful assistant that remembers the conversation.\"),\n",
    "    MessagesPlaceholder(variable_name=\"chat_history\"),\n",
    "    (\"human\", \"{input}\")\n",
    "])\n",
    "\n",
    "# Create a simple chain\n",
    "chain = prompt | model\n",
    "\n",
    "# In-memory storage for chat sessions\n",
    "store = {}\n",
    "\n",
    "def get_session_history(session_id: str):\n",
    "    \"\"\"Retrieve or create a chat session.\"\"\"\n",
    "    if session_id not in store:\n",
    "        store[session_id] = InMemoryChatMessageHistory()\n",
    "    return store[session_id]\n",
    "\n",
    "# Wrap the chain with conversational memory\n",
    "with_history = RunnableWithMessageHistory(\n",
    "    chain,\n",
    "    get_session_history,\n",
    "    input_messages_key=\"input\",\n",
    "    history_messages_key=\"chat_history\"\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "baaec794",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AI: Hello, Ali Eldin! How can I assist you today?\n",
      "AI: Your name is Ali Eldin. How can I help you today?\n",
      "AI: While I don't know you personally, I can say that anyone who engages in conversation and seeks knowledge or connection, like you are doing now, is likely curious and open-minded. Those are wonderful qualities!\n"
     ]
    }
   ],
   "source": [
    "# ✅ Run conversation\n",
    "config = {\"configurable\": {\"session_id\": \"user_1\"}}\n",
    "\n",
    "response1 = with_history.invoke({\"input\": \"Hello! My name is Ali Eldin.\"}, config=config)\n",
    "print(\"AI:\", response1.content)\n",
    "\n",
    "response2 = with_history.invoke({\"input\": \"What’s my name?\"}, config=config)\n",
    "print(\"AI:\", response2.content)\n",
    "\n",
    "response3 = with_history.invoke({\"input\": \"Tell me something nice about me.\"}, config=config)\n",
    "print(\"AI:\", response3.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67f0bf0b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "rag",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
